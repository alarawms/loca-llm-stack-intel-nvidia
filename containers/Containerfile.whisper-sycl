# Containerfile.whisper-sycl — whisper.cpp with SYCL backend for Intel GPUs
#
# Multi-stage build:
#   1. Build whisper.cpp with SYCL support using Intel oneAPI
#   2. Runtime image with just the server binary and Intel GPU libs
#
# Build:
#   podman build -t whisper-sycl:latest -f containers/Containerfile.whisper-sycl .

# ── Stage 1: Build ───────────────────────────────────────────────
FROM docker.io/intel/oneapi-basekit:2025.3.1-0-devel-ubuntu22.04 AS builder

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        git cmake build-essential curl ca-certificates && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /build

# Clone whisper.cpp and build with SYCL
RUN git clone --depth 1 https://github.com/ggml-org/whisper.cpp.git && \
    cd whisper.cpp && \
    cmake -B build \
        -DGGML_SYCL=ON \
        -DCMAKE_C_COMPILER=icx \
        -DCMAKE_CXX_COMPILER=icpx \
        -DCMAKE_BUILD_TYPE=Release && \
    cmake --build build --config Release -j"$(nproc)"

# Download default model (base.en — good speed/quality for iGPU)
RUN cd whisper.cpp && \
    bash models/download-ggml-model.sh base.en

# ── Stage 2: Runtime ─────────────────────────────────────────────
FROM docker.io/intel/oneapi-runtime:2025.3.1-0-devel-ubuntu22.04

# intel-opencl-icd, level-zero, and curl are already in the runtime image
# No extra packages needed — oneapi-runtime 2025.3+ bundles the full compute stack

# Copy built binaries
COPY --from=builder /build/whisper.cpp/build/bin/whisper-server /usr/local/bin/
COPY --from=builder /build/whisper.cpp/build/bin/whisper-cli /usr/local/bin/

# Copy default model
COPY --from=builder /build/whisper.cpp/models/ggml-base.en.bin /models/ggml-base.en.bin

# Intel GPU environment
ENV ONEAPI_DEVICE_SELECTOR=level_zero:gpu \
    ZES_ENABLE_SYSMAN=1 \
    SYCL_CACHE_PERSISTENT=1

EXPOSE 9000

HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -sf http://localhost:9000/health || exit 1

# Default: run server with base.en model on port 9000
# Mount /models to override or add models at runtime
ENTRYPOINT ["whisper-server", \
    "--model", "/models/ggml-base.en.bin", \
    "--host", "0.0.0.0", \
    "--port", "9000"]
